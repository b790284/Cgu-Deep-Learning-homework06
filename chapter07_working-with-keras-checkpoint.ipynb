{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-0.03317106,  0.18923587, -0.22468497,  0.1103363 , -0.21968116,\n",
       "          0.04802659,  0.2788766 , -0.13085268, -0.12916932, -0.1532012 ,\n",
       "         -0.11295083,  0.08026206,  0.17916846, -0.20112205,  0.23091596,\n",
       "         -0.23762347,  0.24796283,  0.25242049,  0.03715155, -0.04621044,\n",
       "          0.28713232,  0.1038942 , -0.11787872,  0.02623966,  0.01367667,\n",
       "          0.08329263,  0.17636228,  0.13563946, -0.2528612 , -0.28234118,\n",
       "         -0.00964844,  0.23578429, -0.15551399, -0.16404416, -0.26819977,\n",
       "          0.22296524,  0.07042104,  0.13505077,  0.25379467, -0.25125125,\n",
       "          0.00335881, -0.17077827, -0.2476293 , -0.15574181,  0.23389214,\n",
       "          0.01983514, -0.10693218, -0.17492585,  0.25321448,  0.09973136,\n",
       "         -0.08827326,  0.10272944, -0.12961173,  0.18549317, -0.22435848,\n",
       "          0.12343398, -0.01077339, -0.28428277, -0.18887042, -0.20557576,\n",
       "         -0.06133425,  0.11036035,  0.16644871, -0.10349993],\n",
       "        [ 0.02386785, -0.07761231,  0.17575788,  0.19642961, -0.26485008,\n",
       "         -0.13033263, -0.2784914 ,  0.2242549 ,  0.21113694, -0.24804483,\n",
       "         -0.2958606 , -0.1102591 ,  0.21051764, -0.16588841, -0.20918873,\n",
       "         -0.05842976, -0.16017447, -0.1325392 ,  0.23242831,  0.2856323 ,\n",
       "          0.27367198,  0.18806276, -0.09576045,  0.0450567 , -0.2627556 ,\n",
       "          0.2604221 , -0.13452195, -0.08845127, -0.28117657,  0.27347875,\n",
       "          0.29800326,  0.0848619 ,  0.2679518 , -0.01645058, -0.14626174,\n",
       "         -0.14561412,  0.08493927,  0.02415067, -0.07778646,  0.2394644 ,\n",
       "         -0.19749019, -0.260539  , -0.2245377 ,  0.06067264,  0.01921615,\n",
       "          0.00677022, -0.25129557, -0.1284806 ,  0.11863309, -0.0776564 ,\n",
       "         -0.26657856,  0.18422511,  0.05051956, -0.04454449, -0.00659314,\n",
       "         -0.25057694,  0.2430141 , -0.0137642 ,  0.26828068, -0.08412975,\n",
       "         -0.06466439,  0.20073843, -0.24763851,  0.08270293],\n",
       "        [ 0.1537087 , -0.04516914,  0.21754837,  0.256796  ,  0.1700337 ,\n",
       "         -0.01802558,  0.26831663,  0.1521422 , -0.05338372, -0.25735345,\n",
       "          0.27039647, -0.04021478, -0.21673945,  0.12545338,  0.18737519,\n",
       "          0.10430622, -0.15877336, -0.21894935, -0.15632828, -0.02491936,\n",
       "         -0.01184174,  0.17288283, -0.1324819 ,  0.06167871,  0.16745985,\n",
       "          0.27262807,  0.21969873,  0.25582314, -0.25126496,  0.04372498,\n",
       "         -0.20026931, -0.05360083,  0.29705173,  0.11457086,  0.12965113,\n",
       "         -0.14059618,  0.25517452, -0.2744981 ,  0.16049483, -0.03471231,\n",
       "         -0.20758098,  0.11474088,  0.28957605, -0.10158597,  0.28092468,\n",
       "         -0.05524759,  0.08480206, -0.25446153, -0.1774427 ,  0.22424805,\n",
       "          0.2934643 , -0.22127157,  0.17212647,  0.16696724, -0.01635182,\n",
       "         -0.1882945 , -0.13815752,  0.06628203,  0.11927414,  0.22078031,\n",
       "         -0.28303617,  0.25435168,  0.08654764,  0.24782807]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[ 0.24734172, -0.17585671,  0.23882613,  0.146855  ,  0.01628557,\n",
       "          0.0131903 ,  0.17426118,  0.16079724, -0.20385872,  0.12903771],\n",
       "        [ 0.22571513,  0.21572384,  0.23661307,  0.01322126,  0.00528169,\n",
       "         -0.04146583,  0.09390742,  0.10899645,  0.09632847,  0.2695311 ],\n",
       "        [ 0.26475433, -0.14883484,  0.03798354, -0.27999082,  0.17503634,\n",
       "          0.06822559, -0.22744216,  0.03808978,  0.09762415,  0.24761644],\n",
       "        [ 0.20638466, -0.02544305,  0.2326115 , -0.18251236,  0.13755879,\n",
       "          0.10068601, -0.22917394, -0.27970445,  0.11619166, -0.2102088 ],\n",
       "        [ 0.13489056,  0.05220765, -0.15926395, -0.12531807,  0.2758995 ,\n",
       "         -0.03423443, -0.18004297, -0.1765257 , -0.18608162, -0.21972746],\n",
       "        [-0.08354348,  0.04337263,  0.15410227,  0.16413492,  0.23549429,\n",
       "          0.0374538 ,  0.01743764,  0.1844624 , -0.19704226, -0.01422182],\n",
       "        [-0.13799247, -0.22653714,  0.0519712 , -0.17254761,  0.05135578,\n",
       "         -0.04246841,  0.045522  ,  0.19401616,  0.1326128 ,  0.06238082],\n",
       "        [-0.17348969, -0.08512889, -0.01999775,  0.18760458, -0.09498067,\n",
       "          0.26680616, -0.10961504,  0.0383732 , -0.26070088,  0.00646418],\n",
       "        [-0.2259632 , -0.1001156 ,  0.1296202 , -0.0041821 , -0.13776906,\n",
       "         -0.08171922, -0.13161437, -0.22489402,  0.14473781, -0.22453815],\n",
       "        [ 0.02641341,  0.13598743, -0.16786876,  0.12324589,  0.07702518,\n",
       "          0.23821792, -0.2741886 ,  0.26909456,  0.23580691,  0.22436205],\n",
       "        [-0.19285357,  0.03584224, -0.19429749, -0.1489201 , -0.09856834,\n",
       "          0.27635434, -0.06036887,  0.05139557,  0.05173331, -0.0226981 ],\n",
       "        [ 0.27613965, -0.02825469,  0.02774376, -0.12260658,  0.25038955,\n",
       "          0.03908896, -0.01971146,  0.09192079, -0.01372725,  0.04226062],\n",
       "        [-0.11466932,  0.137878  , -0.00617084,  0.03804436, -0.21312782,\n",
       "         -0.01987976,  0.07471666,  0.15123174,  0.14739999,  0.02440009],\n",
       "        [ 0.09292328, -0.2756772 , -0.17397185,  0.03671041, -0.008434  ,\n",
       "         -0.03867647, -0.00103566, -0.10360049, -0.16713265, -0.20981267],\n",
       "        [ 0.00044554, -0.04662682,  0.08007136, -0.00755578, -0.2579735 ,\n",
       "          0.03671408,  0.02714971,  0.02748591,  0.03483498, -0.13039012],\n",
       "        [-0.2559023 , -0.02686566,  0.00235146, -0.2802227 , -0.2401252 ,\n",
       "         -0.01697069,  0.25490972,  0.01571253, -0.19648278,  0.06050247],\n",
       "        [ 0.12533224,  0.04701942, -0.1409024 ,  0.12320602,  0.00637668,\n",
       "          0.13492408,  0.08188176, -0.14606333,  0.01476452,  0.06205237],\n",
       "        [-0.20678604, -0.03234807, -0.13786721,  0.22582701, -0.1510525 ,\n",
       "         -0.1049601 , -0.18172538,  0.02293497, -0.05904971, -0.04047458],\n",
       "        [ 0.03623614,  0.12285906, -0.239192  , -0.262423  ,  0.05346814,\n",
       "          0.28361967,  0.08467248, -0.24789782, -0.01107582, -0.15639374],\n",
       "        [ 0.17747512, -0.03606275,  0.23385897, -0.09090394, -0.07787806,\n",
       "          0.18731558, -0.07996015,  0.11517563, -0.22847137, -0.17311488],\n",
       "        [ 0.18668178,  0.12458432, -0.01045933,  0.24517575, -0.14502022,\n",
       "          0.01514897,  0.22179243, -0.02774078,  0.23394218, -0.10773085],\n",
       "        [-0.21398756, -0.16433609,  0.14867422, -0.25640792, -0.260644  ,\n",
       "          0.19902962, -0.03921226,  0.23047665,  0.10491306, -0.07295814],\n",
       "        [ 0.20434344, -0.06227832, -0.191086  ,  0.0544467 ,  0.12656891,\n",
       "         -0.15345204, -0.11688447, -0.12103657, -0.2660606 ,  0.10925007],\n",
       "        [ 0.19337815,  0.15888983, -0.2408965 ,  0.2323142 , -0.05620781,\n",
       "         -0.07550527,  0.03891239, -0.00358102,  0.22335193,  0.2609683 ],\n",
       "        [ 0.06904224, -0.11829433,  0.08749896, -0.2430206 , -0.14670013,\n",
       "         -0.09754471, -0.11189789,  0.12586817, -0.10636337,  0.16986802],\n",
       "        [ 0.23141053,  0.23213086,  0.10873318,  0.142254  , -0.21922249,\n",
       "         -0.02506751, -0.2551494 ,  0.19417202,  0.10960257,  0.20090413],\n",
       "        [-0.02539492, -0.19168173,  0.19495296, -0.13717645, -0.17206593,\n",
       "         -0.22848378,  0.24153969,  0.17181331, -0.14652349,  0.06814611],\n",
       "        [-0.19629186,  0.15426767,  0.14053613,  0.2825832 , -0.0515295 ,\n",
       "          0.22621003,  0.08236274, -0.09838782, -0.06522076,  0.15496475],\n",
       "        [-0.1929962 , -0.19387612, -0.17018697, -0.28416544,  0.10970974,\n",
       "         -0.11228411,  0.27642623, -0.11443089,  0.12401628, -0.1987168 ],\n",
       "        [ 0.27627936, -0.25547436, -0.06121591,  0.05844042,  0.06980756,\n",
       "         -0.1197648 ,  0.24996415,  0.16850257, -0.17003658, -0.16607568],\n",
       "        [-0.26378033,  0.22513136, -0.03798142,  0.02696961, -0.1662103 ,\n",
       "          0.16583318,  0.02066523,  0.04820028, -0.06549577, -0.00110814],\n",
       "        [ 0.19548106,  0.12340012, -0.2804549 , -0.08086701, -0.1953254 ,\n",
       "         -0.18832672, -0.16124788, -0.27569467,  0.12116536, -0.16691995],\n",
       "        [ 0.1085836 , -0.00288448, -0.27935517, -0.21556252, -0.2558157 ,\n",
       "          0.17074609, -0.17345855, -0.06126988, -0.10916725, -0.02062008],\n",
       "        [-0.10174921,  0.0992156 ,  0.26267573,  0.25378403,  0.01360783,\n",
       "          0.06592312,  0.258432  , -0.23017137, -0.15389638,  0.04375294],\n",
       "        [ 0.10134155, -0.08349249,  0.18466383, -0.26476187, -0.12384364,\n",
       "         -0.05171986, -0.09511632, -0.08721383, -0.14998141, -0.18113028],\n",
       "        [-0.0624409 ,  0.25653324,  0.07049105,  0.22710904, -0.13415049,\n",
       "         -0.22854835,  0.0049707 , -0.15522829,  0.11100352,  0.16546988],\n",
       "        [ 0.07217348, -0.22768697,  0.00044468,  0.0534668 ,  0.28235868,\n",
       "          0.27160886,  0.14358225,  0.19408458,  0.14565009,  0.00666678],\n",
       "        [-0.11952515,  0.2029638 , -0.17719312, -0.2214551 , -0.26025316,\n",
       "         -0.01949787,  0.12698954, -0.26189646, -0.2263987 ,  0.1534523 ],\n",
       "        [-0.25887337, -0.04194716,  0.10729262,  0.21189937, -0.16066206,\n",
       "          0.05947611,  0.23450974,  0.12224865, -0.06466582, -0.22106513],\n",
       "        [ 0.15161577, -0.03080386,  0.00759733,  0.09643438,  0.23896202,\n",
       "          0.25218365,  0.02787241,  0.18458638,  0.07960209, -0.00657967],\n",
       "        [ 0.22787586, -0.09905647,  0.0762122 ,  0.2757018 , -0.20424792,\n",
       "          0.2269279 , -0.2672826 ,  0.09550947,  0.02719194, -0.17624247],\n",
       "        [-0.11607537, -0.20091885, -0.10453919, -0.0898412 ,  0.02363002,\n",
       "          0.02755019, -0.17322901, -0.12512118,  0.15719274,  0.12144044],\n",
       "        [ 0.09595528,  0.24643275,  0.03391549, -0.2594108 ,  0.10316586,\n",
       "          0.03477535,  0.27101913,  0.20929128,  0.03245601, -0.24749029],\n",
       "        [ 0.04914436,  0.22815362, -0.27073637, -0.09501578, -0.05792241,\n",
       "         -0.22109005, -0.22773659, -0.16714153, -0.2416455 ,  0.17468706],\n",
       "        [-0.19921708,  0.01036537, -0.1856916 ,  0.24848053,  0.18391448,\n",
       "          0.27448425,  0.07741711, -0.12853749,  0.20764992, -0.05031639],\n",
       "        [ 0.03148377, -0.252976  ,  0.16197667,  0.18542364,  0.17183906,\n",
       "          0.10072905, -0.19354475,  0.135297  , -0.16834384,  0.0413022 ],\n",
       "        [ 0.00306988,  0.20632371, -0.00476819, -0.19060834, -0.19338194,\n",
       "         -0.08280803, -0.07426758,  0.01684836,  0.15424383,  0.01082551],\n",
       "        [-0.12469049, -0.27701157, -0.23389956, -0.20396626,  0.24675527,\n",
       "         -0.15369868, -0.24413873, -0.05994761, -0.2835941 ,  0.1181891 ],\n",
       "        [-0.01496154, -0.02236822,  0.24715897, -0.18090713, -0.19132817,\n",
       "         -0.2255634 , -0.22923668, -0.0462288 , -0.19463891,  0.23381129],\n",
       "        [ 0.10439417,  0.09300265, -0.06609266,  0.00880453,  0.20557746,\n",
       "          0.02413809, -0.26749548, -0.11970921, -0.12100372,  0.19835347],\n",
       "        [ 0.1256446 ,  0.25742993, -0.19680518,  0.0610849 , -0.24552774,\n",
       "         -0.06015006,  0.216553  ,  0.07964271,  0.13645437,  0.03425032],\n",
       "        [ 0.0446786 ,  0.21852937,  0.01691884, -0.02334753, -0.05163887,\n",
       "          0.07884488,  0.12708277,  0.10466424, -0.26833454, -0.23064238],\n",
       "        [-0.07065128,  0.24198005, -0.13043472, -0.27586654,  0.17065343,\n",
       "          0.0238618 , -0.1787549 ,  0.03374472, -0.11259775,  0.2282112 ],\n",
       "        [ 0.11972055, -0.00924575,  0.2576283 , -0.06335489,  0.2070787 ,\n",
       "         -0.04770015,  0.12578112,  0.15959844, -0.02992108, -0.22882044],\n",
       "        [ 0.07102194, -0.16162127,  0.2679272 ,  0.07472163, -0.15280493,\n",
       "          0.2440503 , -0.08236988,  0.25135234, -0.28070867, -0.07092588],\n",
       "        [ 0.11777103, -0.15283778,  0.1349268 ,  0.27347252,  0.00965729,\n",
       "         -0.10554965,  0.09760648,  0.0401409 ,  0.27210066, -0.11466728],\n",
       "        [ 0.02612427,  0.0363068 , -0.27709433, -0.13118531, -0.12064207,\n",
       "          0.22658059, -0.23992988, -0.25446242, -0.23113498,  0.04873553],\n",
       "        [ 0.15867665, -0.14702444,  0.10804191, -0.05512483, -0.23635721,\n",
       "         -0.06907339, -0.15748051, -0.03598474, -0.06510249, -0.09101297],\n",
       "        [ 0.04452506,  0.26460728, -0.03204277,  0.03003502,  0.2393038 ,\n",
       "         -0.22712077,  0.19757906, -0.11307977, -0.07513833,  0.00323907],\n",
       "        [ 0.08458999,  0.00210205,  0.11384869, -0.04088198, -0.10212064,\n",
       "         -0.02731803,  0.0950233 , -0.24906226, -0.27802426, -0.01308027],\n",
       "        [-0.10594735, -0.11797544,  0.00342175, -0.10622332,  0.04334527,\n",
       "         -0.20840417,  0.27741787,  0.27416697,  0.04340717, -0.07505517],\n",
       "        [ 0.24071327, -0.01404047,  0.25999603,  0.15581593,  0.2114175 ,\n",
       "         -0.13006459,  0.02134237, -0.26416376, -0.08699726, -0.17269832],\n",
       "        [-0.14058305,  0.23843476,  0.23890182, -0.2137522 ,  0.19735909,\n",
       "         -0.1861485 ,  0.28265384, -0.10152939, -0.05794881, -0.01299432],\n",
       "        [-0.16305895,  0.2595131 ,  0.06157431, -0.06995487,  0.10393023,\n",
       "          0.12107766, -0.07475944,  0.24722007,  0.17753297,  0.02643764]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_last_layer (Dense)       (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 14ms/step - loss: 28.3606 - priority_loss: 0.3305 - department_loss: 28.0301 - priority_mean_absolute_error: 0.4973 - department_accuracy: 0.3023\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 30.0640 - priority_loss: 0.3339 - department_loss: 29.7301 - priority_mean_absolute_error: 0.5009 - department_accuracy: 0.5539\n",
      "40/40 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 16ms/step - loss: 31.4363 - priority_loss: 0.3339 - department_loss: 31.1024 - priority_mean_absolute_error: 0.5009 - department_accuracy: 0.2719\n",
      "40/40 [==============================] - 1s 4ms/step - loss: 25.8155 - priority_loss: 0.3339 - department_loss: 25.4816 - priority_mean_absolute_error: 0.5009 - department_accuracy: 0.2695\n",
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x21ae2c70730>,\n",
       " <keras.engine.input_layer.InputLayer at 0x21af5fed220>,\n",
       " <keras.engine.input_layer.InputLayer at 0x21af604cfa0>,\n",
       " <keras.layers.merging.concatenate.Concatenate at 0x21af604cbb0>,\n",
       " <keras.layers.core.dense.Dense at 0x21af6046520>,\n",
       " <keras.layers.core.dense.Dense at 0x21aeee93460>,\n",
       " <keras.layers.core.dense.Dense at 0x21af6057400>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 20ms/step - loss: 31.8819 - output_1_loss: 0.3259 - output_2_loss: 31.5560 - output_1_mean_absolute_error: 0.4938 - output_2_accuracy: 0.2734\n",
      "40/40 [==============================] - 1s 8ms/step - loss: 21.9994 - output_1_loss: 0.3322 - output_2_loss: 21.6673 - output_1_mean_absolute_error: 0.4991 - output_2_accuracy: 0.2484\n",
      "40/40 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 11s 6ms/step - loss: 0.2967 - accuracy: 0.9120 - val_loss: 0.1689 - val_accuracy: 0.9514\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1696 - accuracy: 0.9517 - val_loss: 0.1277 - val_accuracy: 0.9663\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1399 - accuracy: 0.9626 - val_loss: 0.1166 - val_accuracy: 0.9700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1105 - accuracy: 0.9721\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2942 - accuracy: 0.9128 - rmse: 7.1812 - val_loss: 0.1512 - val_accuracy: 0.9570 - val_rmse: 7.3618\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1644 - accuracy: 0.9543 - rmse: 7.3558 - val_loss: 0.1209 - val_accuracy: 0.9669 - val_rmse: 7.4014\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1393 - accuracy: 0.9628 - rmse: 7.3878 - val_loss: 0.1127 - val_accuracy: 0.9701 - val_rmse: 7.4199\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1039 - accuracy: 0.9729 - rmse: 7.4318\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2957 - accuracy: 0.9119 - val_loss: 0.1500 - val_accuracy: 0.9573\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1679 - accuracy: 0.9537 - val_loss: 0.1190 - val_accuracy: 0.9686\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1412 - accuracy: 0.9618 - val_loss: 0.1107 - val_accuracy: 0.9728\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1281 - accuracy: 0.9670 - val_loss: 0.1154 - val_accuracy: 0.9714\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1183 - accuracy: 0.9703 - val_loss: 0.1084 - val_accuracy: 0.9747\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1105 - accuracy: 0.9728 - val_loss: 0.1134 - val_accuracy: 0.9746\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1043 - accuracy: 0.9745 - val_loss: 0.1167 - val_accuracy: 0.9756\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1014 - accuracy: 0.9765 - val_loss: 0.1164 - val_accuracy: 0.9779\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.1001 - accuracy: 0.9768 - val_loss: 0.1172 - val_accuracy: 0.9768\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0937 - accuracy: 0.9785 - val_loss: 0.1191 - val_accuracy: 0.9777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21af5fec820>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 16s 9ms/step - loss: 0.2961 - accuracy: 0.9115 - val_loss: 0.1483 - val_accuracy: 0.9581\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1625 - accuracy: 0.9537 - val_loss: 0.1245 - val_accuracy: 0.9669\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1413 - accuracy: 0.9620 - val_loss: 0.1126 - val_accuracy: 0.9704\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1249 - accuracy: 0.9680 - val_loss: 0.1170 - val_accuracy: 0.9720\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1176 - accuracy: 0.9711 - val_loss: 0.1067 - val_accuracy: 0.9751\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1100 - accuracy: 0.9731 - val_loss: 0.1105 - val_accuracy: 0.9760\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1056 - accuracy: 0.9752 - val_loss: 0.1131 - val_accuracy: 0.9783\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1001 - accuracy: 0.9761 - val_loss: 0.1178 - val_accuracy: 0.9766\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0958 - accuracy: 0.9776 - val_loss: 0.1127 - val_accuracy: 0.9779\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0946 - accuracy: 0.9788 - val_loss: 0.1169 - val_accuracy: 0.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a81dd0430>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.2974 - accuracy: 0.9121 - val_loss: 0.1471 - val_accuracy: 0.9572\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1652 - accuracy: 0.9527 - val_loss: 0.1306 - val_accuracy: 0.9655\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1385 - accuracy: 0.9623 - val_loss: 0.1200 - val_accuracy: 0.9682\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1261 - accuracy: 0.9671 - val_loss: 0.1150 - val_accuracy: 0.9728\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.1167 - accuracy: 0.9705 - val_loss: 0.1123 - val_accuracy: 0.9736\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.1092 - accuracy: 0.9732 - val_loss: 0.1077 - val_accuracy: 0.9765\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1067 - accuracy: 0.9743 - val_loss: 0.1105 - val_accuracy: 0.9753\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1010 - accuracy: 0.9758 - val_loss: 0.1113 - val_accuracy: 0.9774\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.0944 - accuracy: 0.9777 - val_loss: 0.1087 - val_accuracy: 0.9781\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0959 - accuracy: 0.9783 - val_loss: 0.1160 - val_accuracy: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a82489cd0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-dfff463d2f783e70\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-dfff463d2f783e70\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9138\n",
      "...loss: 0.2887\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9535\n",
      "...loss: 0.1648\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9636\n",
      "...loss: 0.1387\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9682\n",
      "...val_loss: 0.1257\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation-step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9682\n",
      "...val_loss: 0.1257\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 14s 8ms/step - loss: 0.2932\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.1660\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a831b08b0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.2981 - sparse_categorical_accuracy: 0.9124\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1681 - sparse_categorical_accuracy: 0.9525\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1416 - sparse_categorical_accuracy: 0.9618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a82f55940>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
